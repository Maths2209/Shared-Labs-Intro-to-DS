---
title: "Project"
author: "Dion, Julie, Mia, Vincent"
output: 
    prettydoc::html_pretty:
    theme: cayman
    highlight: github
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(dplyr)
library(ggraph)
library(igraph)
library(factoextra)
library(randomForest)
```

# Exploratory Data Analysis

### Data Cleaning

We will first remove the non-numeric variables: abilities, classification, japanese name, name, primary type, secondary type. Next, we remove "pokedex_number" since it merely indexes the Pokemon, and "base_total" since it is but the sum of the variables: attack, sp_attack, defense, sp_defense, HP, and speed. Finally, we will exclude the variable "percentage_male" because that entry is "NA" for most legendary Pokemon.

```{r}
pokemon <- read.csv("pokemon.csv")[-774,] #Entry 774 has a non-numeric entry in the variable "capture_rate".
summary(is.na(pokemon[pokemon$is_legendary==1,]$percentage_male))
```

```{r}
pokemon_trim <- na.omit(subset(pokemon, select = -c(1, 23, 25, 30, 31, 32, 33, 37, 38)))
pokemon_trim$capture_rate <- as.numeric(levels(pokemon_trim$capture_rate)[pokemon_trim$capture_rate])
```

### Principal Component Analysis (PCA)


We suspect that there is significant multicollinearity between many of our variables: e.g. height and weight, attack and sp_attack, defense and sp_defense and much more. Therefore, we perform PCA to check for multicollinearity in our data. Note that all the PCAs we perform will be scaled and centered.

```{r}
pca <- prcomp(pokemon_trim, scale. = TRUE)
fviz_eig(pca)
fviz_pca_var(pca,
             col.var = "contrib", # Color by contributions to the PC
             gradient.cols = c("#00AFBB", "#E7B800", "#FC4E07"),
             repel = TRUE,    # Avoid text overlapping
             select.var = list(contrib = 10)
)
```

Plotting the 10 variables which contribute most to the first two principal components, we can already see that legendary status may be positively correlated with the variables: height, weight, base_egg_steps, sp_attack, and attack.

Let us combine some of our variables. We will combine the "against" variables with the "defense", "HP", and "sp_defense" variables to form the "avg_ehp" (average effective HP) variable. We will also combine the "attack" and "sp_attack" variables to form the "avg_attack" (average attack) variable. We based the derivation of our new variables on the way damage is calculated in the main Pokemon games (see https://bulbapedia.bulbagarden.net/wiki/Damage#Damage_calculation).

```{r}
pokemon_trimandcombine <- subset(pokemon_trim, select = -c(1:19,23,26:28))
avg_multiplier <- rowMeans(pokemon_trim[,1:18])
pokemon_trimandcombine$avg_ehp <- ((pokemon_trim$hp*pokemon_trim$defense + pokemon_trim$hp*pokemon_trim$sp_defense)/200)/avg_multiplier
pokemon_trimandcombine$avg_attack <- (pokemon_trim$sp_attack + pokemon_trim$attack)/2
```

Now, let us re-perform PCA.

```{r}
pca_trimandcombine <- prcomp(pokemon_trimandcombine, scale. = TRUE)
fviz_eig(pca_trimandcombine)
fviz_pca_var(pca_trimandcombine,
             col.var = "contrib", # Color by contributions to the PC
             gradient.cols = c("#00AFBB", "#E7B800", "#FC4E07"),
             repel = TRUE,     # Avoid text overlapping
             select.var = list(contrib = 10)
)
```

The correlations look much stronger now.

```{r}
pokemon_trimandcombine_pred <- subset(pokemon_trimandcombine, select = -9)
pca_trimandcombine_pred <- prcomp(pokemon_trimandcombine_pred, scale. = TRUE)
fviz_eig(pca_trimandcombine_pred)
fviz_pca_var(pca_trimandcombine_pred,
             col.var = "contrib", # Color by contributions to the PC
             gradient.cols = c("#00AFBB", "#E7B800", "#FC4E07"),
             repel = TRUE,     # Avoid text overlapping
             select.var = list(contrib = 10)
)
```

Unfortunately, our PCA plots, especially this plot without the dependent variable "is_legendary", indicate significant multicollinearity between the predictors, especially between the variables: speed, avg_attack, avg_ehp, base_egg_steps, height, and weight.

It should be noted though that PCA is quite sensitive to outliers and unfortunately there are extreme outliers in the data for the variables: height, weight, base_egg_steps, avg_ehp, base_happiness, and experience_growth. The variable base_happiness also appears to be a poor predictor since there is little variance in its data apart from extreme outliers.

```{r}
hist(pokemon_trimandcombine$height_m)
hist(pokemon_trimandcombine$weight_kg)
hist(pokemon_trimandcombine$speed)
hist(pokemon_trimandcombine$avg_ehp)
hist(pokemon_trimandcombine$avg_attack)
hist(pokemon_trimandcombine$base_egg_steps)
hist(pokemon_trimandcombine$base_happiness)
hist(pokemon_trimandcombine$capture_rate)
hist(pokemon_trimandcombine$experience_growth)
```

We do not remove the outliers because many of them are data points for legendary pokemon, and we already have concerningly few data points for legendary Pokemon.

Fun fact: There is a spike in the number of legendary Pokemon in generation 7. Though we cannot make strong conclusions here since the data comprises of only 7 points.

```{r}
avg_legend <- vector(mode = "numeric", 7)
for (i in 1:7) {
  avg_legend[i] = sum(pokemon_trim[pokemon_trim$generation==i,]$is_legendary)/length(pokemon_trim[pokemon_trim$generation==i,]$is_legendary)
}
plot(avg_legend)
```

# Classification Methods

### Consideration of Logistic Regression

We now want to create a model to classify legendary Pokemon. We would rather use random forests than a logistic regression for three main reasons: 

1) multicollinearity of predictors adversely affects the results from the logistic model whereas the random forest method is robust against the multicollinearity of predictors,

2) given the number of variables we have, overfitting/model selection is a major concern. The random forest method deals with overfitting well.

3) we would like to include the categorical variables: type1 and type2 in our model (we initially removed these variables because they are non-numeric). For a logistic regression, this can only be done by creating 35 binary variables which is extremely troublesome and aggravates the overfitting/model selection problem. The random forest method is naturally suited for categorical variables.

While ridge regularisation can ameliorate these problems for logistic regression, a random forest model remains easier to implement and should be more accurate.


```{r}
length(unique(pokemon$type1))
length(unique(pokemon$type2))
```

### Decision Tree Model

We will construct a decision tree model before progressing to a random forest model.

```{r}
pokemon_trimandcombine <- subset(pokemon_trimandcombine, select = -12)
pokemon_trimandcombine <- transform(pokemon_trimandcombine, is_legendary = as.factor(is_legendary))

# split the trim data set into training set and validation set, with the ratio: 7:3 
set.seed(100)
train <- sample(nrow(pokemon_trimandcombine), 0.7*nrow(pokemon_trimandcombine), replace = FALSE)
TrainSet2 <- pokemon_trimandcombine[train,]
ValidSet2 <- pokemon_trimandcombine[-train,]

library(rpart.plot)
model1_trim <- rpart(is_legendary ~ ., 
                data = TrainSet2,
                method = "class",
                control=rpart.control(minsplit=20, cp = .01),
                parms=list(split='information'))
rpart.plot(model1_trim)
```

Let us examine its accuracy and confusion matrix. 

```{r}
predValid1_trim <- predict(model1_trim, ValidSet2, type = "class")
# Checking classification accuracy
mean(predValid1_trim == ValidSet2$is_legendary)                    
table(predValid1_trim,ValidSet2$is_legendary)
```

### Random Forest Model

Now, we will implement the random forest model. 

```{r}
model2 <- randomForest(is_legendary ~ ., data = TrainSet2, importance = TRUE, na.action=na.exclude)
model2
```

Let us see its accuracy and confusion matrix. 

```{r}
# Predicting on Validation set
predValid2 <- predict(model2, ValidSet2, type = "class")
# Checking classification accuracy
mean(predValid2 == ValidSet2$is_legendary)                    
table(predValid2,ValidSet2$is_legendary)
```

```{r}
# Finetuning the model by finding the right mtry for model which gives us greater predictive power
result2=c()

for (i in 3:10) {
  model2 <- randomForest(is_legendary ~ ., data = TrainSet2, ntree = 500, mtry = i, importance = TRUE)
  predValid2 <- predict(model2, ValidSet2, type = "class")
  result2[i-2] = mean(predValid2 == ValidSet2$is_legendary)
}
 
plot(3:10,result2)
```

mtry = 3 produces very accurate results and further increases in mtry do not increase the accuracy, therefore, we will use mtry = 3.

```{r}
model_final2 <- randomForest(is_legendary ~ ., data = TrainSet2, importance = TRUE, na.action=na.exclude, mtry = 3)
```

Finally, let us visualise a tree from the random forest using the function "tree_func" taken from https://shiring.github.io/machine_learning/2017/03/16/rf_plot_ggraph.

```{r, warning = FALSE}
tree_func <- function(final_model,
                      tree_num) {
  
  # get tree by index
  tree <- randomForest::getTree(final_model, 
                                k = tree_num, 
                                labelVar = TRUE) %>%
    tibble::rownames_to_column() %>%
    # make leaf split points to NA, so the 0s won't get plotted
    mutate(`split point` = ifelse(is.na(prediction), `split point`, NA))
  
  # prepare data frame for graph
  graph_frame <- data.frame(from = rep(tree$rowname, 2),
                            to = c(tree$`left daughter`, tree$`right daughter`))
  
  # convert to graph and delete the last node that we don't want to plot
  graph <- graph_from_data_frame(graph_frame) %>%
    delete_vertices("0")
  
  # set node labels
  V(graph)$node_label <- gsub("_", " ", as.character(tree$`split var`))
  V(graph)$leaf_label <- as.character(tree$prediction)
  V(graph)$split <- as.character(round(tree$`split point`, digits = 2))
  
  # plot
  plot <- ggraph(graph, 'dendrogram') + 
    theme_bw() +
    geom_edge_link() +
    geom_node_point() +
    geom_node_text(aes(label = node_label), na.rm = TRUE, repel = TRUE) +
    geom_node_label(aes(label = split), vjust = 2.5, na.rm = TRUE, fill = "white") +
    geom_node_label(aes(label = leaf_label, fill = leaf_label), na.rm = TRUE, 
					repel = TRUE, colour = "white", fontface = "bold", show.legend = FALSE) +
    theme(panel.grid.minor = element_blank(),
          panel.grid.major = element_blank(),
          panel.background = element_blank(),
          plot.background = element_rect(fill = "white"),
          panel.border = element_blank(),
          axis.line = element_blank(),
          axis.text.x = element_blank(),
          axis.text.y = element_blank(),
          axis.ticks = element_blank(),
          axis.title.x = element_blank(),
          axis.title.y = element_blank(),
          plot.title = element_text(size = 18))
  
  print(plot)
}
tree_func(model_final2, 2)
```