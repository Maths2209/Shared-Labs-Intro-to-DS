---
title: "Lab 3"
author: Mia Raghavan, Julie Yoonju Jung, Dion, Vincent Fung 
date: 30/08/2019
output: 
    prettydoc::html_pretty:
    theme: cayman
    highlight: github
---

# Exercise 1
*Familiarize yourself with the data.*

```{r}
library(dplyr)
data <- read.csv("cs-training-NAs-removed.csv")
```

The dataset consists information about each person that can possibly be used to predict whether that person will experience financial distress in the next two years - and hence whether that person is credit worthy.

# Exercise 2
*What is in the first column of the data frame that you created by reading in the CSV file? Do you expect this variable to be useful to predict credit worthiness?*

The first column consists of the index of each person in the dataset. Since the index was assigned arbitrarily and is interchangable between persons, it is not useful in predicting the credit worthiness of a person.

# Exercise 3
*Fit a logistic regression with SeriousDlqin2yrs as dependent variable and MonthlyIncome as the only predictor. Interpret the estimated parameter for MonthlyIncome in plain English. Is the sign (positive versus negative) of this parameter estimate as you would have expected beforehand?*

```{r}
logit<-glm(data$SeriousDlqin2yrs~data$MonthlyIncome, family=binomial)
summary(logit)
```

For every increase in the monthly income of a person by 1 unit, the log-odds decreases by 4.541e-05, where the probability is that of a person experiencing financial distress in the next two years. 

The negative sign indicates that a person with a greater monthly income will have a lower probability of experiencing financial distress in the next two years. The negative sign is expected and makes intuitive sense.

# Exercise 4
*Consider the model fit from Exercise 3. Create a side-by-side boxplot of the predicted probabilities seperated out by whether the persion actually had a serious delinquency (SeriousDlqin2yrs==1) or not. What do you think of the usefulness of this model fit to determine credit worthiness?*

```{r}
data_withprob<-data
data_withprob$PredictedProbability<-predict(logit, type="response")
boxplot(data_withprob$PredictedProbability ~ data_withprob$SeriousDlqin2yrs)
```

The model is not useful because the left and right boxplots both show a massive number of outliers in the predicted probability which indicates that we will attain many false positives and false negatives respectively.

# Exercise 5
*Consider the side-by-side boxplots from Exercise 4. Define SeriousDlqin2yrs == 1 as a positive. Using a probability threshold of 0.5 for classification, how many true positives would you get? How many false positives would you get? How many true negatives will you get? How many false negatives will you get?*

```{r}
all(data_withprob$PredictedProbability<0.5)
summary(data$SeriousDlqin2yrs == 1)
```

Since the predicted probability is less than the probability threshold of 0.5 for every person, every person is predicted to not experience financial distress in the next two years. Since we have 0 positives, we have 0 true or false positives. We have 8357 false negatives, which are simply the negatives in the dataset, and we have 111912 true negatives, which are the positives in the dataset.

# Exercise 6
*Plot the ROC curve of the model fit from Exercise 4 and compute the corresponding area under the curve (AUC). Do these results support the answer that you give in Exercise 4 to the question “What do you think of the usefulness of this model fit to determine credit worthiness?” Please explain why or why not.*

```{r}
library(ROCR)
predObj = prediction(data_withprob$PredictedProbability, data_withprob$SeriousDlqin2yrs)
rocObj = performance(predObj, measure="tpr", x.measure="fpr")
aucObj = performance(predObj, measure="auc")
plot(rocObj, main = paste("Area under the curve:",
round(aucObj@y.values[[1]] ,4)))
abline(0,1, col = "red")
```

We want our model to have an AUC which is close to 1 as that indicates a low false positive rate and a high true positive rate. The model we have however, has an AUC 0.576 which is very far from 1. This supports out belief that the model is not useful. In fact, the ROC curve we attain is quite similar to the line y=x (in red) which indicates that the model's predictions are not much better than predictions made from coin flips.

# Exercise 7
*Fit a logistic regression with SeriousDlqin2yrs as dependent variable and as predictor all other variables in the dataset. Plot the ROC curve and compute the AUC. How do the ROC curve and AUC compare to the results from Exercise 6? Was this to be expected? Why or why not?*

```{r}
data_withoutX <- subset(data, select = -X)
logit_all<-glm(SeriousDlqin2yrs~., data = data_withoutX, family=binomial)
data_withprob2<-data_withoutX
data_withprob2$PredictedProbability<-predict(logit_all, type="response")
predObj = prediction(data_withprob2$PredictedProbability, data_withprob$SeriousDlqin2yrs)
rocObj = performance(predObj, measure="tpr", x.measure="fpr")
aucObj = performance(predObj, measure="auc")
plot(rocObj, main = paste("Area under the curve:",
round(aucObj@y.values[[1]] ,4)))
abline(0,1, col = "red")
```

The ROC curve is now much further from the line y=x (in red) and the AUC is now 0.6912 which is greater than the original 0.576 and closer to 1. These indicate that the model is making better predictions than before. This is to be expected since the model is drawing upon more data to make its predictions (since we added more predictors).

# Exercise 8
*In linear regression, the coefficients are determined by minimizing the sum of the squared residuals. Give a conceptual description of how the coefficients are determined for the logistic regression fit from the previous exercise.*

The coefficients for the logistic regression fit are determined by maximising the AUC.