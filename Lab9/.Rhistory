wc <- read.csv(file = "Womens Clothing E-Commerce Reviews.csv",na.strings = c("", "NA"), stringsAsFactors = FALSE)
# Create Corpus
corpus <- VCorpus(VectorSource(wc$Review.Text))
clean_corpus <- function(corpus){
corpus <- tm_map(corpus, content_transformer(tolower))
corpus <- tm_map(corpus, removePunctuation)
corpus <- tm_map(corpus, removeNumbers)
corpus <- tm_map(corpus, removeWords, stopwords("en"))
corpus <- tm_map(corpus, stemDocument)
corpus <- tm_filter(corpus, FUN = function(x) content(x) != "NA")
return(corpus)
}
ccleaned <- clean_corpus(corpus)
ccleaned
wc <- wc[!is.na(wc$Review.Text),] #Delete any reviews with no text in the dataframe.
dtm <- TermDocumentMatrix(ccleaned)
m <- as.matrix(dtm)
v <- sort(rowSums(m),decreasing=TRUE)
d <- data.frame(word = names(v),freq=v)
head(d, 10)
View(m)
d2 <- d %>% mutate(log_freq = log(freq)) %>%
mutate(perc_freq = freq / length(ccleaned) * 100)
p <- ggplot(d2, aes(x = reorder(word, -freq), y = log_freq)) +
geom_bar(stat = "identity")
p
subset_words <- d2[10 < d2$perc_freq & d2$perc_freq < 20,]
subset_words
wc <- read.csv(file = "ecommerce_women.csv",na.strings = c("", "NA"), stringsAsFactors = FALSE)
# Create Corpus
corpus <- VCorpus(VectorSource(wc$Review.Text))
clean_corpus <- function(corpus){
corpus <- tm_map(corpus, content_transformer(tolower))
corpus <- tm_map(corpus, removePunctuation)
corpus <- tm_map(corpus, removeNumbers)
corpus <- tm_map(corpus, removeWords, stopwords("en"))
corpus <- tm_map(corpus, stemDocument)
corpus <- tm_filter(corpus, FUN = function(x) content(x) != "NA")
return(corpus)
}
ccleaned <- clean_corpus(corpus)
wc <- read.csv(file = "ecommerce_women.csv",na.strings = c("", "NA"), stringsAsFactors = FALSE)
# Create Corpus
corpus <- VCorpus(VectorSource(wc$Review.Text))
clean_corpus <- function(corpus){
corpus <- tm_map(corpus, content_transformer(tolower))
corpus <- tm_map(corpus, removePunctuation)
corpus <- tm_map(corpus, removeNumbers)
corpus <- tm_map(corpus, removeWords, stopwords("en"))
corpus <- tm_map(corpus, stemDocument)
corpus <- tm_filter(corpus, FUN = function(x) content(x) != "NA")
return(corpus)
}
ccleaned <- clean_corpus(corpus)
ccleaned
wc <- wc[!is.na(wc$Review.Text),] #Delete any reviews with no text in the dataframe.
ccleaned <- clean_corpus(corpus)
dtm <- TermDocumentMatrix(ccleaned)
dtm <- TermDocumentMatrix(ccleaned)
m <- as.matrix(dtm)
v <- sort(rowSums(m),decreasing=TRUE)
d <- data.frame(word = names(v),freq=v)
head(d, 10)
d2 <- d %>% mutate(log_freq = log(freq)) %>%
mutate(perc_freq = freq / length(ccleaned) * 100)
subset_words <- d2[10 < d2$perc_freq & d2$perc_freq < 20,]
View(subset_words)
View(d)
View(d2)
wc <- read.csv(file = "Womens Clothing E-Commerce Reviews.csv",na.strings = c("", "NA"), stringsAsFactors = FALSE)
# Create Corpus
corpus <- VCorpus(VectorSource(wc$Review.Text))
clean_corpus <- function(corpus){
corpus <- tm_map(corpus, content_transformer(tolower))
corpus <- tm_map(corpus, removePunctuation)
corpus <- tm_map(corpus, removeNumbers)
corpus <- tm_map(corpus, removeWords, stopwords("en"))
corpus <- tm_map(corpus, stemDocument)
corpus <- tm_filter(corpus, FUN = function(x) content(x) != "NA")
return(corpus)
}
ccleaned <- clean_corpus(corpus)
ccleaned
wc <- wc[!is.na(wc$Review.Text),] #Delete any reviews with no text in the dataframe.
dtm <- TermDocumentMatrix(ccleaned)
m <- as.matrix(TermDocumentMatrix(ccleaned))
v <- sort(rowSums(m),decreasing=TRUE)
d <- data.frame(word = names(v),freq=v)
head(d, 10)
m <- as.matrix(TermDocumentMatrix(ccleaned))
v <- rowSums(m)
d <- data.frame(word = names(v),freq=v)
head(d, 10)
m <- as.matrix(TermDocumentMatrix(ccleaned))
v <- sort(rowSums(m),decreasing=TRUE)
d <- data.frame(word = names(v),freq=v)
head(d, 10)
names(v)
knitr::opts_chunk$set(echo = TRUE)
library(knitr)       # used to make kable tables
library(tm)
library(SnowballC)
library(dplyr)
library(wordcloud)
library(RColorBrewer)
library(ggplot2)
wc <- read.csv(file = "Womens Clothing E-Commerce Reviews.csv",na.strings = c("", "NA"), stringsAsFactors = FALSE)
# Create Corpus
corpus <- VCorpus(VectorSource(wc$Review.Text))
clean_corpus <- function(corpus){
corpus <- tm_map(corpus, content_transformer(tolower))
corpus <- tm_map(corpus, removePunctuation)
corpus <- tm_map(corpus, removeNumbers)
corpus <- tm_map(corpus, removeWords, stopwords("en"))
corpus <- tm_map(corpus, stemDocument)
corpus <- tm_filter(corpus, FUN = function(x) content(x) != "NA")
return(corpus)
}
ccleaned <- clean_corpus(corpus)
ccleaned
wc <- wc[!is.na(wc$Review.Text),] #Delete any reviews with no text in the dataframe.
m <- as.matrix(TermDocumentMatrix(ccleaned))
v <- sort(rowSums(m),decreasing=TRUE)
d <- data.frame(word = names(v),freq=v)
head(d, 10)
View(d)
sum(freq)
sum(d$freq)
d2 <- d %>% mutate(log_freq = log(freq)) %>%
mutate(perc_freq = freq / sum(freq) * 100)
subset_words <- d2[10 < d2$perc_freq & d2$perc_freq < 20,]
subset_words
subset_words
length(ccleaned)
d2 <- d %>% mutate(log_freq = log(freq)) %>%
mutate(perc_freq = freq / length(ccleaned) * 100)
p <- ggplot(d2, aes(x = reorder(word, -freq), y = log_freq)) +
geom_bar(stat = "identity")
p
subset_words <- d2[10 < d2$perc_freq & d2$perc_freq < 20,]
subset_words
set.seed(1234)
wordcloud(words = subset_words$word, freq = subset_words$freq,
random.order=FALSE, scale=c(4,.5),
colors=brewer.pal(8, "Dark2"))
length(dtm_tfidf)
dtm_tfidf<- DocumentTermMatrix(ccleaned, control = list(weighting = weightTfIdf))
length(dtm_tfidf)
length(dtm_tfidf)
M_norm<- as.matrix(DocumentTermMatrix(ccleaned, control = list(weighting = weightTfIdf)))
M_norm[0,4]
M_norm[1,4]
M_norm[9,4]
M_norm[6,4]
M_norm
dtm_tfidf<- DocumentTermMatrix(ccleaned, control = list(weighting = weightTfIdf))
dim(dtm_tfidf)
v2 <- sort(rowSums(dtm_tfidf),decreasing=TRUE)
v2 <- sort(rowSums(dtm_tfidf),decreasing=TRUE)
dim(dtm_tfidf)
dtm_tfidf
as.matrix(dtm_tfidf)
dtm_tfidf$dimnames
dtm_tfidf$nrow
dtm_tfidf$i
dtm_tfidf$j
sum(dtm_tfidf$j)
dtm_tfidf<- DocumentTermMatrix(corpus, control = list(weighting = function(x) weightTfIdf(x, normalize = TRUE)))
dtm_tfidf<- DocumentTermMatrix(corpus, control = list(weighting = function(x) weightTfIdf(x, normalize = TRUE)))
dtm_tfidf
m <- as.matrix(DocumentTermMatrix(ccleaned))
knitr::opts_chunk$set(echo = TRUE)
library(knitr)       # used to make kable tables
library(tm)
library(SnowballC)
library(dplyr)
library(wordcloud)
library(RColorBrewer)
library(ggplot2)
wc <- read.csv(file = "Womens Clothing E-Commerce Reviews.csv",na.strings = c("", "NA"), stringsAsFactors = FALSE)
# Create Corpus
corpus <- VCorpus(VectorSource(wc$Review.Text))
clean_corpus <- function(corpus){
corpus <- tm_map(corpus, content_transformer(tolower))
corpus <- tm_map(corpus, removePunctuation)
corpus <- tm_map(corpus, removeNumbers)
corpus <- tm_map(corpus, removeWords, stopwords("en"))
corpus <- tm_map(corpus, stemDocument)
corpus <- tm_filter(corpus, FUN = function(x) content(x) != "NA")
return(corpus)
}
ccleaned <- clean_corpus(corpus)
ccleaned
wc <- wc[!is.na(wc$Review.Text),] #Delete any reviews with no text in the dataframe.
m <- as.matrix(DocumentTermMatrix(ccleaned))
v <- sort(colSums(m),decreasing=TRUE)
d <- data.frame(word = names(v),freq=v)
head(d, 10)
v <- sort(rowSums(m),decreasing=TRUE)
m <- as.matrix(DocumentTermMatrix(ccleaned))
v <- sort(rowSums(m),decreasing=TRUE)
d <- data.frame(word = names(v),freq=v)
head(d, 10)
m <- as.matrix(DocumentTermMatrix(ccleaned))
v <- sort(colSums(m),decreasing=TRUE)
d <- data.frame(word = names(v),freq=v)
head(d, 10)
d2 <- d %>% mutate(log_freq = log(freq)) %>%
mutate(perc_freq = freq / length(ccleaned) * 100)
p <- ggplot(d2, aes(x = reorder(word, -freq), y = log_freq)) +
geom_bar(stat = "identity")
p
subset_words <- d2[10 < d2$perc_freq & d2$perc_freq < 20,]
set.seed(1234)
wordcloud(words = subset_words$word, freq = subset_words$freq,
random.order=FALSE, scale=c(4,.5),
colors=brewer.pal(8, "Dark2"))
dtm_tfidf<- DocumentTermMatrix(corpus, control = list(weighting = function(x) weightTfIdf(x, normalize = TRUE)))
dim(dtm_tfidf)
dim(dtm_tfidf)
dtm_tfidf$nrow
dtm_tfidf$ncol
dtm_tfidf$i
dtm_tfidf$j
dtm_tfidf$v
?DocumentTermMatrix
m <- as.matrix(DocumentTermMatrix(ccleaned), bounds = c(0.1*length(ccleaned), 0.2*length(ccleaned)))
m <- as.matrix(DocumentTermMatrix(ccleaned), bounds = c(0.1*length(ccleaned), 0.2*length(ccleaned)))
v <- sort(colSums(m),decreasing=TRUE)
v <- sort(colSums(m),decreasing=TRUE)
d <- data.frame(word = names(v),freq=v)
d <- data.frame(word = names(v),freq=v)
head(d, 10)
d <- data.frame(word = names(v),freq=v)
m <- as.matrix(DocumentTermMatrix(ccleaned), bounds = c(0.1*length(ccleaned), 0.2*length(ccleaned)))
View(d)
View(d)
v <- sort(colSums(m),decreasing=TRUE)
d <- data.frame(word = names(v),freq=v)
head(d, 10)
m <- as.matrix(DocumentTermMatrix(ccleaned), bounds = c(0.1*length(ccleaned), 0.2*length(ccleaned)))
v <- sort(colSums(m),decreasing=TRUE)
d <- data.frame(word = names(v),freq=v)
m <- as.matrix(DocumentTermMatrix(ccleaned), control = list(bounds = c(0.1*length(ccleaned), 0.2*length(ccleaned))))
v <- sort(colSums(m),decreasing=TRUE)
d <- data.frame(word = names(v),freq=v)
0.1*length(ccleaned)
0.2*length(ccleaned))
0.2*length(ccleaned)
m <- as.matrix(DocumentTermMatrix(ccleaned, control = list(bounds = c(0.1*length(ccleaned), 0.2*length(ccleaned)))))
m <- as.matrix(DocumentTermMatrix(ccleaned, control = list(bounds = c(0.1*length(ccleaned), 0.2*length(ccleaned)))))
m <- as.matrix(DocumentTermMatrix(ccleaned, control = bounds = c(0.1*length(ccleaned), 0.2*length(ccleaned))))
m <- as.matrix(DocumentTermMatrix(ccleaned, bounds = c(0.1*length(ccleaned), 0.2*length(ccleaned))))
m <- as.matrix(DocumentTermMatrix(ccleaned, control = list(bounds = c(0.1*length(ccleaned), 0.2*length(ccleaned)))))
m <- DocumentTermMatrix(ccleaned, control = list(bounds = c(0.1*length(ccleaned), 0.2*length(ccleaned))))
m <- DocumentTermMatrix(ccleaned,
control = list(bounds =
c(0.1*length(ccleaned),
0.2*length(ccleaned))))
m <- DocumentTermMatrix(ccleaned,
control = list(bounds =
c(0,1000)))
m <- DocumentTermMatrix(ccleaned, control=list(bounds = list(global = c(0.1*length(ccleaned),0.2*length(ccleaned)))))
as.matrix(m)
dim(as.matrix(m))
d <- data.frame(word = names(v),freq=v)
m <- DocumentTermMatrix(ccleaned, control=list(bounds = list(global = c(0.1*length(ccleaned),0.2*length(ccleaned)))))
v <- sort(colSums(m),decreasing=TRUE)
m <- as.matrix(DocumentTermMatrix(ccleaned, control=list(bounds = list(global = c(0.1*length(ccleaned),0.2*length(ccleaned))))))
v <- sort(colSums(m),decreasing=TRUE)
d <- data.frame(word = names(v),freq=v)
head(d, 10)
wordcloud(words = d$word, freq = d$freq,
random.order=FALSE, scale=c(4,.5),
colors=brewer.pal(8, "Dark2"))
0.1*length(ccleaned)
0.2*length(ccleaned)
head(d, 10)
dtm_tfidf <- DocumentTermMatrix(corpus, control = list(bounds = list(global = c(0.1*length(ccleaned),0.2*length(ccleaned))), weighting = function(x) weightTfIdf(x, normalize = TRUE)))
dtm_tfidf$i
dtm_tfidf$nrow
dtm_tfidf$ncol
dtm_tfidf <- DocumentTermMatrix(corpus, control = list(bounds = list(global = c(0.1*length(ccleaned),0.2*length(ccleaned))), weighting = function(x) weightTfIdf(x, normalize = TRUE)))
dtm_tfidf <- DocumentTermMatrix(ccleaned, control = list(bounds = list(global = c(0.1*length(ccleaned),0.2*length(ccleaned))), weighting = function(x) weightTfIdf(x, normalize = TRUE)))
dtm_tfidf$ncol
dtm_tfidf$nrow
dtm_tfidf$ncol
dtm_tfidf$i
dtm_tfidf$j
dtm_tfidf$v
length(dtm_tfidf$v)
dim(dtm_tfidf$v)
length
length(dtm_tfidf$v)
length(dtm_tfidf$v)/27
length(dtm_tfidf$v)
as.matrix(dtm_tfidf)
dtm_tfidf <- as.matrix(DocumentTermMatrix(ccleaned, control = list(bounds = list(global = c(0.1*length(ccleaned),0.2*length(ccleaned))), weighting = function(x) weightTfIdf(x, normalize = TRUE))))
dim(dtm_tfidf)
logit <- glm(wc$Recommended.IND ~ ., data = dtm_tfidf, family=binomial)
dtm_tfidf <- as.dataframeDocumentTermMatrix(ccleaned, control = list(bounds = list(global = c(0.1*length(ccleaned),0.2*length(ccleaned))), weighting = function(x) weightTfIdf(x, normalize = TRUE))))
dtm_tfidf <- as.dataframe(DocumentTermMatrix(ccleaned, control = list(bounds = list(global = c(0.1*length(ccleaned),0.2*length(ccleaned))), weighting = function(x) weightTfIdf(x, normalize = TRUE))))
dtm_tfidf <- as.data.frame(DocumentTermMatrix(ccleaned, control = list(bounds = list(global = c(0.1*length(ccleaned),0.2*length(ccleaned))), weighting = function(x) weightTfIdf(x, normalize = TRUE))))
View(dtm_tfidf)
logit <- glm(wc$Recommended.IND ~ ., data = dtm_tfidf, family=binomial)
View(dtm_tfidf)
dtm_tfidf <- as.data.frame(DocumentTermMatrix(ccleaned, control = list(bounds = list(global = c(0.1*length(ccleaned),0.2*length(ccleaned))), weighting = function(x) weightTfIdf(x, normalize = TRUE))))
dtm_tfidf <- as.data.frame(DocumentTermMatrix(ccleaned, control = list(bounds = list(global = c(0.1*length(ccleaned),0.2*length(ccleaned))), weighting = function(x) weightTfIdf(x, normalize = TRUE))))
dtm_tfidf <- as.matrix.data.frame(DocumentTermMatrix(ccleaned, control = list(bounds = list(global = c(0.1*length(ccleaned),0.2*length(ccleaned))), weighting = function(x) weightTfIdf(x, normalize = TRUE))))
dtm_tfidf <- as.matrix](DocumentTermMatrix(ccleaned, control = list(bounds = list(global = c(0.1*length(ccleaned),0.2*length(ccleaned))), weighting = function(x) weightTfIdf(x, normalize = TRUE))))
dtm_tfidf <- as.matrix](DocumentTermMatrix(ccleaned, control = list(bounds = list(global = c(0.1*length(ccleaned),0.2*length(ccleaned))), weighting = function(x) weightTfIdf(x, normalize = TRUE))))
dtm_tfidf <- as.matrix(DocumentTermMatrix(ccleaned, control = list(bounds = list(global = c(0.1*length(ccleaned),0.2*length(ccleaned))), weighting = function(x) weightTfIdf(x, normalize = TRUE))))
View(dtm_tfidf)
knitr::opts_chunk$set(echo = TRUE)
library(knitr)       # used to make kable tables
library(tm)
library(SnowballC)
library(dplyr)
library(wordcloud)
library(RColorBrewer)
library(ggplot2)
wc <- read.csv(file = "Womens Clothing E-Commerce Reviews.csv",na.strings = c("", "NA"), stringsAsFactors = FALSE)
# Create Corpus
corpus <- VCorpus(VectorSource(wc$Review.Text))
clean_corpus <- function(corpus){
corpus <- tm_map(corpus, content_transformer(tolower))
corpus <- tm_map(corpus, removePunctuation)
corpus <- tm_map(corpus, removeNumbers)
corpus <- tm_map(corpus, removeWords, stopwords("en"))
corpus <- tm_map(corpus, stemDocument)
corpus <- tm_filter(corpus, FUN = function(x) content(x) != "NA")
return(corpus)
}
ccleaned <- clean_corpus(corpus)
ccleaned
wc <- wc[!is.na(wc$Review.Text),] #Delete any reviews with no text in the dataframe.
m <- as.matrix(DocumentTermMatrix(ccleaned))
v <- sort(colSums(m),decreasing=TRUE)
d <- data.frame(word = names(v),freq=v)
head(d, 10)
d2 <- d %>% mutate(log_freq = log(freq)) %>%
mutate(perc_freq = freq / length(ccleaned) * 100)
p <- ggplot(d2, aes(x = reorder(word, -freq), y = log_freq)) +
geom_bar(stat = "identity")
p
m <- as.matrix(DocumentTermMatrix(ccleaned, control=list(bounds = list(global = c(0.1*length(ccleaned),0.2*length(ccleaned))))))
v <- sort(colSums(m),decreasing=TRUE)
d <- data.frame(word = names(v),freq=v)
head(d, 10)
set.seed(1234)
wordcloud(words = d$word, freq = d$freq,
random.order=FALSE, scale=c(4,.5),
colors=brewer.pal(8, "Dark2"))
dtm_tfidf <- as.matrix(DocumentTermMatrix(ccleaned, control = list(bounds = list(global = c(0.1*length(ccleaned),0.2*length(ccleaned))), weighting = function(x) weightTfIdf(x, normalize = TRUE))))
View(dtm_tfidf)
dtm_tfidf <- as.data.frame(dtm_tfidf)
?glm
?DocumentTermMatrix
View(dtm_tfidf)
dtm_tfidf <- as.data.frame(dtm_tfidf)
dtm_tfidf <- as.matrix(DocumentTermMatrix(ccleaned, control = list(bounds = list(global = c(0.1*length(ccleaned),0.2*length(ccleaned))), weighting = function(x) weightTfIdf(x, normalize = TRUE))))
dtm_tfidf <- as.matrix(DocumentTermMatrix(ccleaned, control = list(bounds = list(global = c(0.1*length(ccleaned),0.2*length(ccleaned))), weighting = function(x) weightTfIdf(x, normalize = TRUE))))
dtm_tfidf <- as.data.frame(dtm_tfidf)
dtm_tfidf$outcome <- wc$Recommended.IND
View(dtm_tfidf)
logit <- glm(wc$Recommended.IND ~ ., family=binomial)
logit <- glm(Recommended.IND ~ ., data = wc, family=binomial)
summary(logit)
logit <- glm(outcome ~ ., data = wc, family=binomial)
logit <- glm(outcome ~ ., data = dtm_tfidf, family=binomial)
summary(logit)
dtm_tfidf <- DocumentTermMatrix(ccleaned, control = list(bounds = list(global = c(0.1*length(ccleaned),0.2*length(ccleaned))), weighting = function(x) weightTfIdf(x, normalize = TRUE)))
dtm_tfidf$i
dtm_tfidf$j
dtm_tfidf$v
dtm_tfidf <- as.matrix(DocumentTermMatrix(ccleaned, control = list(bounds = list(global = c(0.1*length(ccleaned),0.2*length(ccleaned))), weighting = function(x) weightTfIdf(x, normalize = TRUE))))
dtm_tfidf <- as.data.frame(dtm_tfidf)
dtm_tfidf$outcome <- wc$Recommended.IND
logit <- glm(outcome ~ ., data = dtm_tfidf, family=binomial)
summary(logit)
wc_withprob <- wc
library(ROCR)
wc_withprob <- wc
wc_withprob$PredictedProbability <- predict(logit, type="response")
predObj = prediction(wc_withprob$PredictedProbability, wc_withprob$SeriousDlqin2yrs)
library(ROCR)
PredictedProbability <- predict(logit, type="response")
predObj = prediction(PredictedProbability, dtm_tfidf$outcome)
rocObj = performance(predObj, measure="tpr", x.measure="fpr")
aucObj = performance(predObj, measure="auc")
plot(rocObj, main = paste("Area under the curve:",
round(aucObj@y.values[[1]] ,4)))
pandoc -v
pandoc
install.packages(c("backports", "callr", "curl", "digest", "ellipsis", "hms", "htmltools", "knitr", "pkgconfig", "purrr", "RcppArmadillo", "rlang", "rmarkdown", "RWeka", "RWekajars", "testthat", "tidyr", "tinytex", "xfun"))
warn
knitr::opts_chunk$set(echo = TRUE)
library(knitr)       # used to make kable tables
library(tm)
library(SnowballC)
library(dplyr)
library(wordcloud)
library(RColorBrewer)
library(ggplot2)
options(warn=-1)
knitr::opts_chunk$set(echo = TRUE)
library(knitr)       # used to make kable tables
library(tm)
library(SnowballC)
library(dplyr)
library(wordcloud)
library(RColorBrewer)
library(ggplot2)
wc <- read.csv(file = "Womens Clothing E-Commerce Reviews.csv",na.strings = c("", "NA"), stringsAsFactors = FALSE)
# Create Corpus
corpus <- VCorpus(VectorSource(wc$Review.Text))
clean_corpus <- function(corpus){
corpus <- tm_map(corpus, content_transformer(tolower))
corpus <- tm_map(corpus, removePunctuation)
corpus <- tm_map(corpus, removeNumbers)
corpus <- tm_map(corpus, removeWords, stopwords("en"))
corpus <- tm_map(corpus, stemDocument)
corpus <- tm_filter(corpus, FUN = function(x) content(x) != "NA")
return(corpus)
}
ccleaned <- clean_corpus(corpus)
ccleaned
wc <- wc[!is.na(wc$Review.Text),] #Delete any reviews with no text in the dataframe.
m <- as.matrix(DocumentTermMatrix(ccleaned))
v <- sort(colSums(m),decreasing=TRUE)
d <- data.frame(word = names(v),freq=v)
head(d, 10)
hist_data <- d %>% mutate(log_freq = log(freq)) %>%
mutate(perc_freq = freq / length(ccleaned) * 100)
p <- ggplot(hist_data, aes(x = reorder(word, -freq), y = log_freq)) + geom_bar(stat = "identity") + theme(axis.title.x = element_blank())
p
m <- as.matrix(DocumentTermMatrix(ccleaned, control=list(bounds = list(global = c(0.1*length(ccleaned),0.2*length(ccleaned))))))
v <- sort(colSums(m),decreasing=TRUE)
d <- data.frame(word = names(v),freq=v)
head(d, 10)
set.seed(1234)
wordcloud(words = d$word, freq = d$freq,
random.order=FALSE, scale=c(4,.5),
colors=brewer.pal(8, "Dark2"))
dtm_tfidf <- as.matrix(DocumentTermMatrix(ccleaned, control = list(bounds = list(global = c(0.1*length(ccleaned),0.2*length(ccleaned))), weighting = function(x) weightTfIdf(x, normalize = TRUE))))
dtm_tfidf <- as.data.frame(dtm_tfidf)
dtm_tfidf$outcome <- wc$Recommended.IND
logit <- glm(outcome ~ ., data = dtm_tfidf, family=binomial)
summary(logit)
library(ROCR)
PredictedProbability <- predict(logit, type="response")
predObj = prediction(PredictedProbability, dtm_tfidf$outcome)
rocObj = performance(predObj, measure="tpr", x.measure="fpr")
aucObj = performance(predObj, measure="auc")
plot(rocObj, main = paste("Area under the curve:",
round(aucObj@y.values[[1]] ,4)))
options(warn=-1)
p <- ggplot(hist_data, aes(x = reorder(word, -freq), y = log_freq)) + geom_bar(stat = "identity") + theme(axis.label.x = element_blank())
p <- ggplot(hist_data, aes(x = reorder(word, -freq), y = log_freq)) + geom_bar(stat = "identity") + theme(axis.lab.x = element_blank())
p <- ggplot(hist_data, aes(x = reorder(word, -freq), y = log_freq)) + geom_bar(stat = "identity") + theme(xlab = element_blank())
View(hist_data)
p <- ggplot(hist_data, aes(x = reorder(word, -freq), y = log_freq)) + geom_bar(stat = "identity") + scale_x_discrete(breaks = seq(0, 10, by = 0.5))
hist_data <- d %>% mutate(log_freq = log(freq)) %>%
mutate(perc_freq = freq / length(ccleaned) * 100)
p <- ggplot(hist_data, aes(x = reorder(word, -freq), y = log_freq)) + geom_bar(stat = "identity") + scale_x_discrete(breaks = seq(0, 10, by = 0.5))
p
hist_data <- d %>% mutate(log_freq = log(freq)) %>%
mutate(perc_freq = freq / length(ccleaned) * 100)
p <- ggplot(hist_data, aes(x = reorder(word, -freq), y = log_freq)) + geom_bar(stat = "identity")
p
hist_data <- d %>% mutate(log_freq = log(freq)) %>%
mutate(perc_freq = freq / length(ccleaned) * 100)
p <- ggplot(hist_data, aes(x = reorder(word, -freq), y = log_freq)) + geom_bar(stat = "identity")
p
m <- as.matrix(DocumentTermMatrix(ccleaned))
v <- sort(colSums(m),decreasing=TRUE)
d <- data.frame(word = names(v),freq=v)
head(d, 10)
hist_data <- d %>% mutate(log_freq = log(freq)) %>%
mutate(perc_freq = freq / length(ccleaned) * 100)
p <- ggplot(hist_data, aes(x = reorder(word, -freq), y = log_freq)) + geom_bar(stat = "identity") + scale_x_discrete(breaks = seq(0, 10, by = 0.5))
p
hist_data <- d %>% mutate(log_freq = log(freq)) %>%
mutate(perc_freq = freq / length(ccleaned) * 100)
p <- ggplot(hist_data, aes(x = reorder(word, -freq), y = log_freq)) + geom_bar(stat = "identity")
p
hist_data <- d %>% mutate(log_freq = log(freq)) %>%
mutate(perc_freq = freq / length(ccleaned) * 100)
p <- ggplot(hist_data, aes(x = reorder(word, -freq), y = log_freq)) + geom_bar(stat = "identity") + scale_x_discrete(breaks = seq(0, 10, by = 0.5))
p
options(warn=-1)
summary(d)
d <- data.frame(word = names(v),freq=v)
summary(d)
d
length(d)
length(d$word)
m <- as.matrix(DocumentTermMatrix(ccleaned, control=list(bounds = list(global = c(0.1*length(ccleaned),0.2*length(ccleaned))))))
v <- sort(colSums(m),decreasing=TRUE)
d <- data.frame(word = names(v),freq=v)
length(d$word)
d
knitr::opts_chunk$set(echo = TRUE)
library(knitr)       # used to make kable tables
library(tm)
library(SnowballC)
library(dplyr)
library(wordcloud)
library(RColorBrewer)
library(ggplot2)
library(ROCR)
options(warn=0)
